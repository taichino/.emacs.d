#name : q4m
# --
#!/opt/local/bin/python2.5
# -*- coding: utf-8 -*-

import pymysql, MySQLdb
import urllib
from BeautifulSoup import BeautifulSoup

'''
CREATE TABLE url (
  id int(10) unsigned NOT NULL AUTO_INCREMENT,
  url varchar(255) NOT NULL,
  title TEXT DEFAULT NULL,
  PRIMARY KEY (id),
  UNIQUE KEY url (url)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

CREATE TABLE `crawler_queue` (
  `id` int(10) unsigned NOT NULL,
  `fail_cnt` int(11) NOT NULL DEFAULT 0
) ENGINE=QUEUE DEFAULT CHARSET=utf8;

DELIMITER |

CREATE TRIGGER update_crawler_queue AFTER INSERT ON url
  FOR EACH ROW BEGIN
    INSERT INTO crawler_queue SET id=NEW.id;
  END;
|

DELIMITER ;
'''

def main():
  con = pymysql.connect(host='localhost', db='crawler_test', user='crawler_user', passwd='crawler_pass')
  cur = con.cursor()
  if cur.execute('SELECT queue_wait("crawler_queue")'):
    cur.execute('SELECT * FROM crawler_queue')
    url_id = cur.fetchone()[0]
    cur.execute('SELECT url FROM url WHERE id = %s', (url_id,))
    url = cur.fetchone()
    if url:
      soup = BeautifulSoup(urllib.urlopen(url[0]).read())
      title = soup.find('title').decodeContents().strip()
      cur.execute("UPDATE url SET title = '%s' WHERE id = %s", (title, url_id))
      con.commit()
  cur.execute('SELECT queue_end()')

if __name__ == '__main__':
  main()
